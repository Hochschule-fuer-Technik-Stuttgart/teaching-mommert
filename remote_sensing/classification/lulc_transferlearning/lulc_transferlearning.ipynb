{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning for Supervised Classification with Sentinel-2 Satellite Imagery\n",
    "\n",
    "Michael Mommert, Stuttgart University of Applied Sciences, 2025\n",
    "\n",
    "This Notebook introduces the concept of transfer learning and shows how it can be applied to different image classification tasks based on Sentinel-2 satellite images from the [*ben-ge-800* dataset](https://zenodo.org/records/12941231). This Notebook follows very closely the [Image classification with a Convolutional Neural Network for Sentinel-2 Satellite Imagery](https://github.com/Hochschule-fuer-Technik-Stuttgart/teaching-mommert/blob/main/remote_sensing/classification/lulc_cnn/lulc_cnn.ipynb) Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy \\\n",
    "    scipy \\\n",
    "    pandas \\\n",
    "    matplotlib \\\n",
    "    rasterio \\\n",
    "    scikit-learn \\\n",
    "    torch \\\n",
    "    torchmetrics \\\n",
    "    tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Download\n",
    "\n",
    "We're setting up our Python environment for this tutorial by installing and importing the necessary modules and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wi5NrxiUYT_m"
   },
   "outputs": [],
   "source": [
    "# system level modules for handling files and file structures\n",
    "import os\n",
    "import tarfile\n",
    "import copy\n",
    "\n",
    "# scipy ecosystem imports for numerics, data handling and plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# pytorch and helper modules\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# utils\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# rasterio for reading in satellite image data\n",
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We download the *ben-ge-800* dataset and unpack it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://zenodo.org/records/12941231/files/ben-ge-800.tar.gz?download=1 -O ben-ge-800.tar.gz\n",
    "  \n",
    "tarfile = tarfile.open('ben-ge-800.tar.gz')  # open ben-ge-800 tarball \n",
    "tarfile.extractall('./', filter='data')  # extract tarball\n",
    "\n",
    "data_base_path = os.path.join(os.path.abspath('.'), 'ben-ge-800')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvTJ9WPQOxon"
   },
   "source": [
    "**ben-ge-800** contains samples for 800 locations with co-located Sentinel-1 SAR data, Sentinel-2 multispectral data, elevation data, land-use/land-cover data, as well as environmental data. **ben-ge-800** is a subset of the much larger **ben-ge** dataset (see [https://github.com/HSG-AIML/ben-ge](https://github.com/HSG-AIML/ben-ge) for details.) We deliberately use a very small subset of **ben-ge** to enable reasonable runtimes for the examples shown in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yver4nem5anJ"
   },
   "source": [
    "The environment is now set up and the data in place. Before we define the dataset classes and dataloaders to access the data efficiently, we fix some random seeds to obtain reproduceable results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dOZcKSCT5anJ"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)     # sets the seed value in Numpy\n",
    "torch.manual_seed(42)  # sets the seed value in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4UnJK1N5anJ"
   },
   "source": [
    "## Data Handling\n",
    "\n",
    "Before we start implementing our model, let's have a look at the data. In this notebook, we need two different data products that are available for every single sample in the dataset:\n",
    "* Sentinel-2 multispectral data: 12-band Level-2A images of size 120x120; we will restrict ourselves to the 4 bands that carry 10m-resolution imaging data (bands 2, 3, 4 and 8)\n",
    "* [ESAWorldCover](https://esa-worldcover.org/en) land-use/land-cover image labels: for each image, this label consists of the most common (based on area covered in the image) land-use/land-cover class in the image; there are 11 different classes in total.\n",
    "\n",
    "We will train a image classification model to predict this land-use/land-cover label for each image. \n",
    "\n",
    "For this purpose, we modify our dataset class from the Notebook [Image classification with a Convolutional Neural Network for Sentinel-2 Satellite Imagery](https://github.com/Hochschule-fuer-Technik-Stuttgart/teaching-mommert/blob/main/remote_sensing/classification/lulc_cnn/lulc_cnn.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdVdNb2qP7OQ"
   },
   "outputs": [],
   "source": [
    "# define labels of the different lulc labels\n",
    "ewc_label_names = [\"tree_cover\", \"shrubland\", \"grassland\", \"cropland\", \"built-up\",\n",
    "                   \"bare/sparse_vegetation\", \"snow_and_ice\",\"permanent_water_bodies\",\n",
    "                   \"herbaceous_wetland\", \"mangroves\",\"moss_and_lichen\"]\n",
    "\n",
    "class BENGE(Dataset):\n",
    "    \"\"\"A dataset class implementing the Sentinel-1, Sentinel-2 and ESAWorldCover data modalities.\"\"\"\n",
    "    def __init__(self, \n",
    "                 data_dir=data_base_path, \n",
    "                 split='train',\n",
    "                 s2_bands=[2, 3, 4, 8]):\n",
    "        \"\"\"Dataset class constructor\n",
    "\n",
    "        keyword arguments:\n",
    "        data_dir -- string containing the path to the base directory of ben-ge dataset, default: ben-ge-800 directory\n",
    "        split    -- string, describes the split to be instantiated, either `train`, `val` or `test`\n",
    "        s2_bands -- list of Sentinel-2 bands to be extracted, default: all bands\n",
    "\n",
    "        returns:\n",
    "        BENGE object\n",
    "        \"\"\"\n",
    "        super(BENGE, self).__init__()\n",
    "\n",
    "        # store some definitions\n",
    "        self.s2_bands = s2_bands\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "        # read in relevant data files and definitions\n",
    "        self.name = self.data_dir.split(\"/\")[-1]\n",
    "        self.split = split\n",
    "        self.meta = pd.read_csv(f\"{self.data_dir}/{self.name}_meta.csv\")\n",
    "\n",
    "        # extract prevalent lulc label for each sample\n",
    "        ewc = pd.read_csv(f\"{self.data_dir}/{self.name}_esaworldcover.csv\")\n",
    "        self.meta.loc[:, 'lulc'] = np.argmax(ewc.loc[:, 'tree_cover':'moss_and_lichen'].values, axis=1)\n",
    "        \n",
    "        # we shuffle the indices in the meta file and then select the first 500 samples for training, 150 for validation and 150 for testing\n",
    "        if split == 'train':\n",
    "            self.meta = self.meta.iloc[0:500]\n",
    "        if split == 'val':\n",
    "            self.meta = self.meta.iloc[500:650]\n",
    "        if split == 'test':\n",
    "            self.meta = self.meta.iloc[650:800]\n",
    "       \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return sample `idx` as dictionary from the dataset.\"\"\"\n",
    "        sample_info = self.meta.iloc[idx]\n",
    "        patch_id = sample_info.patch_id  # extract Sentinel-2 patch id\n",
    "\n",
    "        # retrieve Sentinel-2 data\n",
    "        s2 = np.empty((4, 120, 120))\n",
    "        for i, band in enumerate(self.s2_bands):\n",
    "            with rio.open(f\"{self.data_dir}/sentinel-2/{patch_id}/{patch_id}_B0{band}.tif\") as dataset:\n",
    "                data = dataset.read(1)\n",
    "            s2[i,:,:] = data\n",
    "        s2 = np.clip(s2.astype(float) / 10000, 0, 1)  # normalize Sentinel-2 data\n",
    "        \n",
    "        # create sample dictionary containing all the data\n",
    "        sample = {\n",
    "            \"patch_id\": patch_id,  # Sentinel-2 id of this patch\n",
    "            \"s2\": torch.from_numpy(s2).float(),  # Sentine;-2 data [4, 120, 120]\n",
    "            \"lulc\": torch.tensor(sample_info.lulc).long(),  # most prevalent ESA WorldCover lulc class\n",
    "            }\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return length of this dataset.\"\"\"\n",
    "        return self.meta.shape[0]\n",
    "\n",
    "    def display(self, idx):\n",
    "        \"\"\"Method to display a data sample, consisting of the Sentinel-2 image.\n",
    "        \n",
    "        positional arguments:\n",
    "        idx -- sample index\n",
    "        \"\"\"\n",
    "\n",
    "        # retrieve sample\n",
    "        sample = self[idx]\n",
    "\n",
    "        f, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "        \n",
    "        # display Sentinel-2 image\n",
    "        img_rgb = np.dstack(sample['s2'][0:3].numpy()[::-1])  # extract RGB, reorder, and perform a deep stack (shape: 120, 120, 3)\n",
    "        ax.imshow((img_rgb-np.min(img_rgb))/(np.max(img_rgb)-np.min(img_rgb)))\n",
    "        ax.set_title(ewc_label_names[sample['lulc'].numpy()])\n",
    "        ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XShJZLzc5anM"
   },
   "source": [
    "We can now instantiate the different splits for this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PygqMbD05anN"
   },
   "outputs": [],
   "source": [
    "train_data = BENGE(split='train')\n",
    "val_data = BENGE(split='val')\n",
    "test_data = BENGE(split='test')\n",
    "\n",
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmzCS6cP5anN"
   },
   "source": [
    "We can retrieve a single sample simply by indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6iJ4PFY5anN"
   },
   "outputs": [],
   "source": [
    "train_data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a sample from our dataset contains both the image data and a `lulc` key, which represents the most common land-use/land-cover class in this image.\n",
    "\n",
    "Let's display the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.display(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCfRser65anN"
   },
   "source": [
    "This checks out. The image indeed contains a lot of grassland areas.\n",
    "\n",
    "For Neural Network training we have to define data loaders. When we do so, we have to define the batch size, which is typically limited by the GPU RAM during training. For evaluation purposes, we can typically pick a larger batch size, since we need less memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vigNcosR5anO"
   },
   "outputs": [],
   "source": [
    "train_batchsize = 8\n",
    "eval_batchsize = 16\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=train_batchsize, num_workers=4, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=eval_batchsize, num_workers=4, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=eval_batchsize, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8_bVEfRpM4W"
   },
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOK06D2caPjB"
   },
   "source": [
    "We build a very simple Convolutional Neural Network that consists of 3 convolutional layers and two linear layers to learn the image classification task (see [Image classification with a Convolutional Neural Network for Sentinel-2 Satellite Imagery](https://github.com/Hochschule-fuer-Technik-Stuttgart/teaching-mommert/blob/main/remote_sensing/classification/lulc_cnn/lulc_cnn.ipynb) for details). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GaJLON_ckFW_"
   },
   "outputs": [],
   "source": [
    "class BENGENet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BENGENet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(4, 8, 5, stride=2) # 4 channels to 8 channels with a kernel size of 5\n",
    "        self.conv2 = nn.Conv2d(8, 16, 5, stride=2) # 4 channels to 8 channels with a kernel size of 5\n",
    "        \n",
    "        self.linear1 = nn.Linear(16*6*6, 100, bias=True)\n",
    "        self.linear2 = nn.Linear(100, 11, bias=True)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(2)  # maxpooling by a factor of 2\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # convolutional layers\n",
    "        x = self.maxpool(self.relu(self.conv1(x)))\n",
    "        x = self.maxpool(self.relu(self.conv2(x)))\n",
    "\n",
    "        # reshape feature maps for linear layers\n",
    "        x = x.view(-1, 16*6*6)\n",
    "\n",
    "        # linear layers\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.logsoftmax(self.linear2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we instantiate the model and we're ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xm1HYSr5anO"
   },
   "outputs": [],
   "source": [
    "model = BENGENet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy_LH3aUpM4Z"
   },
   "source": [
    "## Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F66Xr5Xy5anP"
   },
   "source": [
    "The goal of this tutorial is to introduce the concept of transfer learning.\n",
    "\n",
    "In order to see, whether transfer learning has any impact on our results, we first train our model from scratch on the land-use/land-cover labels extract above. This model will serve as our **baseline** against which we will compare our fine-tuned model below. \n",
    "\n",
    "First of all, let's verify if a GPU is available on our compute machine. If not, the CPU will be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xb_5oxnbcId"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device used: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gl4509B-8kIZ"
   },
   "source": [
    "Before we can implement the training pipeline we have to define two more things: a Loss function and an optimizer that will update our model weights during training. We also define our evaluation metric, for which we use the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJvU_eEr5anP"
   },
   "outputs": [],
   "source": [
    "# we will use the cross entropy loss\n",
    "loss = nn.NLLLoss()\n",
    "\n",
    "# we will use the Adam optimizer\n",
    "learning_rate = 0.0001\n",
    "opt = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# we instantiate the accuracy metric\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mxynwEl5anP"
   },
   "source": [
    "Now, we have to move the model and the loss function on the GPU, since the computationally heavy work will be conducted there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAXnEvAu5anP"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "loss.to(device)\n",
    "accuracy.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEbPAZwn5anQ"
   },
   "source": [
    "Finally, we can implement our training pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wn8Kiqd-iR3l"
   },
   "outputs": [],
   "source": [
    "epochs = 30  # training for 30 epochs\n",
    "\n",
    "train_losses_epochs = []\n",
    "val_losses_epochs = []\n",
    "train_accs_epochs = []\n",
    "val_accs_epochs = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    # we perform training for one epoch\n",
    "    model.train()   # it is very important to put your model into training mode!\n",
    "    for samples in tqdm(train_dataloader):\n",
    "        # we extract the input data (Sentinel-2)\n",
    "        x = samples['s2'].to(device)\n",
    "\n",
    "        # now we extract the target (lulc class) and move it to the gpu\n",
    "        y = samples['lulc'].to(device)\n",
    "\n",
    "        # we make a prediction with our model\n",
    "        output = model(x)\n",
    "\n",
    "        # we reset the graph gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # we determine the classification loss\n",
    "        loss_train = loss(output, y)\n",
    "\n",
    "        # we run a backward pass to comput the gradients\n",
    "        loss_train.backward()\n",
    "\n",
    "        # we update the network paramaters\n",
    "        opt.step()\n",
    "\n",
    "        # we write the mini-batch loss and accuracy into the corresponding lists\n",
    "        train_losses.append(loss_train.detach().cpu())\n",
    "        train_accs.append(accuracy(torch.argmax(output, dim=1), y).detach().cpu())\n",
    "\n",
    "    # we evaluate the current state of the model on the validation dataset\n",
    "    model.eval()   # it is very important to put your model into evaluation mode!\n",
    "    with torch.no_grad():\n",
    "        for samples in tqdm(val_dataloader):\n",
    "            # we extract the input data (Sentinel-2)\n",
    "            x = samples['s2'].to(device)\n",
    "\n",
    "            # now we extract the target (lulc class) and move it to the gpu\n",
    "            y = samples['lulc'].to(device)\n",
    "\n",
    "            # we make a prediction with our model\n",
    "            output = model(x)\n",
    "\n",
    "            # we determine the classification loss\n",
    "            loss_val = loss(output, y)\n",
    "\n",
    "            # we write the mini-batch loss and accuracy into the corresponding lists\n",
    "            val_losses.append(loss_val.detach().cpu())\n",
    "            val_accs.append(accuracy(torch.argmax(output, dim=1), y).detach().cpu())\n",
    "\n",
    "    train_losses_epochs.append(np.mean(train_losses))\n",
    "    train_accs_epochs.append(np.mean(train_accs))\n",
    "    val_losses_epochs.append(np.mean(val_losses))\n",
    "    val_accs_epochs.append(np.mean(val_accs))\n",
    "\n",
    "    print(\"epoch {}: train: loss={}, acc={}; val: loss={}, acc={}\".format(\n",
    "        ep, train_losses_epochs[-1], train_accs_epochs[-1], \n",
    "        val_losses_epochs[-1], val_accs_epochs[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4S81HUFy5anQ"
   },
   "source": [
    "Training progress looks good: train and validation losses are decreasing, accuracies are increasing.\n",
    "\n",
    "Let's plot the available metrics as a function of the number of training iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hApnOKv5anQ"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, sharex=True, figsize=(10,5))\n",
    "\n",
    "ax[0].plot(np.arange(1, len(train_losses_epochs)+1), train_losses_epochs, label='Train', color='blue')\n",
    "ax[0].plot(np.arange(1, len(val_losses_epochs)+1), val_losses_epochs, label='Val', color='red')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(np.arange(1, len(train_accs_epochs)+1), train_accs_epochs, label='Train', color='blue')\n",
    "ax[1].plot(np.arange(1, len(val_accs_epochs)+1), val_accs_epochs, label='Val', color='red')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2x-UByx5anQ"
   },
   "source": [
    "The model learns well and we stopped the learning process before overfitting sets in. Let's evaluate the model again on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k18Zn4Ff5anR"
   },
   "outputs": [],
   "source": [
    "test_accs = []\n",
    "\n",
    "model.eval()   # it is very important to put your model into evaluation mode!\n",
    "with torch.no_grad():\n",
    "    for samples in tqdm(test_dataloader):\n",
    "        x = samples['s2'].to(device)\n",
    "\n",
    "        # now we extract the target (lulc class) and move it to the gpu\n",
    "        y = samples['lulc'].to(device)\n",
    "\n",
    "        # we make a prediction with our model\n",
    "        output = model(x)\n",
    "\n",
    "        # we determine the classification loss\n",
    "        loss_val = loss(output, y)\n",
    "\n",
    "        # we write the mini-nbatch loss and accuracy into the corresponding lists\n",
    "        test_accs.append(accuracy(torch.argmax(output, dim=1), y).cpu().numpy())\n",
    "\n",
    "print('test dataset accuracy:', np.mean(test_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test dataset accuracy is very close to the validation dataset accuracy, which is a good sign: the model generalizes well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyfLhN0O5anR"
   },
   "source": [
    "## Transfer Learning\n",
    "\n",
    "Now we will introduce transfer learning. The idea behind transfer learning is to not start your model training from scratch, but to train a model that has been previously and successfully trained on a different taks and/or a different dataset. This process is called **fine-tuning**.\n",
    "\n",
    "We will utilize a model that is almost identical to our `BENGENet`: the difference is that it features an output of length 10 instead of 11. This is an important detail: it means that we cannot squeeze the pretrained model into our existing architecture. We have to modify the `BENGENet` architecture to accommodate the pretrained model, fill it with the pretrained model's parameters and then we have to modify this final linear layer again to make it compatible with our land-use/land-cover data. That means that the weights in this final linear layer will not be pretrained. But since all other layers use the existing pretrained weights, we should nevertheless notice a benefit.\n",
    "\n",
    "The model that we will be using is trained on the same dataset that we are using. Therefore, we don't have to modify the first convolutional layer (e.g., due to a different number of bands). The model was trained on an image classification task to predict the climatezone in which the images are located. We will read the weights from that pretrained model (from file `bengenet_climatezones.pth`) into our modified version of the `BENGENet` architecture: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BENGENet()  # we instantiate the model\n",
    "model.linear2 = nn.Linear(100, 10, bias=True)  # we modify the final layer, due to the different number of classes\n",
    "model.load_state_dict(torch.load('bengenet_climatezones.pth', weights_only=False))  # we read in the pretrained model and copy the weights\n",
    "model.linear2 = nn.Linear(100, 11, bias=True)  # we modify the final layer again to accommodate our 11 lulc classes\n",
    "\n",
    "model.to(device)  # we move the model instance to the GPU\n",
    "opt = optim.Adam(params=model.parameters(), lr=learning_rate)  # we tell the optimizer to modify the weights of the new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pretrained model is now on the GPU and we can start the fine-tuning process. The code we use for fine-tuning is identical to our training routine from above.\n",
    "\n",
    "For better comparability, we fine-tune the model also for 30 epochs and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30  # training for 30 epochs\n",
    "\n",
    "train_losses_epochs = []\n",
    "val_losses_epochs = []\n",
    "train_accs_epochs = []\n",
    "val_accs_epochs = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    # we perform training for one epoch\n",
    "    model.train()   # it is very important to put your model into training mode!\n",
    "    for samples in tqdm(train_dataloader):\n",
    "        # we extract the input data (Sentinel-2)\n",
    "        x = samples['s2'].to(device)\n",
    "\n",
    "        # now we extract the target (lulc class) and move it to the gpu\n",
    "        y = samples['lulc'].to(device)\n",
    "\n",
    "        # we make a prediction with our model\n",
    "        output = model(x)\n",
    "\n",
    "        # we reset the graph gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # we determine the classification loss\n",
    "        loss_train = loss(output, y)\n",
    "\n",
    "        # we run a backward pass to comput the gradients\n",
    "        loss_train.backward()\n",
    "\n",
    "        # we update the network paramaters\n",
    "        opt.step()\n",
    "\n",
    "        # we write the mini-batch loss and accuracy into the corresponding lists\n",
    "        train_losses.append(loss_train.detach().cpu())\n",
    "        train_accs.append(accuracy(torch.argmax(output, dim=1), y).detach().cpu())\n",
    "\n",
    "    # we evaluate the current state of the model on the validation dataset\n",
    "    model.eval()   # it is very important to put your model into evaluation mode!\n",
    "    with torch.no_grad():\n",
    "        for samples in tqdm(val_dataloader):\n",
    "            # we extract the input data (Sentinel-2)\n",
    "            x = samples['s2'].to(device)\n",
    "\n",
    "            # now we extract the target (lulc class) and move it to the gpu\n",
    "            y = samples['lulc'].to(device)\n",
    "\n",
    "            # we make a prediction with our model\n",
    "            output = model(x)\n",
    "\n",
    "            # we determine the classification loss\n",
    "            loss_val = loss(output, y)\n",
    "\n",
    "            # we write the mini-batch loss and accuracy into the corresponding lists\n",
    "            val_losses.append(loss_val.detach().cpu())\n",
    "            val_accs.append(accuracy(torch.argmax(output, dim=1), y).detach().cpu())\n",
    "\n",
    "    train_losses_epochs.append(np.mean(train_losses))\n",
    "    train_accs_epochs.append(np.mean(train_accs))\n",
    "    val_losses_epochs.append(np.mean(val_losses))\n",
    "    val_accs_epochs.append(np.mean(val_accs))\n",
    "\n",
    "    print(\"epoch {}: train: loss={}, acc={}; val: loss={}, acc={}\".format(\n",
    "        ep, train_losses_epochs[-1], train_accs_epochs[-1], \n",
    "        val_losses_epochs[-1], val_accs_epochs[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, sharex=True, figsize=(10,5))\n",
    "\n",
    "ax[0].plot(np.arange(1, len(train_losses_epochs)+1), train_losses_epochs, label='Train', color='blue')\n",
    "ax[0].plot(np.arange(1, len(val_losses_epochs)+1), val_losses_epochs, label='Val', color='red')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(np.arange(1, len(train_accs_epochs)+1), train_accs_epochs, label='Train', color='blue')\n",
    "ax[1].plot(np.arange(1, len(val_accs_epochs)+1), val_accs_epochs, label='Val', color='red')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how smooth the loss functions are. This is a result of the fact that the model was pretrained. Let's compare the test dataset accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accs = []\n",
    "\n",
    "model.eval()   # it is very important to put your model into evaluation mode!\n",
    "with torch.no_grad():\n",
    "    for samples in tqdm(test_dataloader):\n",
    "        x = samples['s2'].to(device)\n",
    "\n",
    "        # now we extract the target (lulc class) and move it to the gpu\n",
    "        y = samples['lulc'].to(device)\n",
    "\n",
    "        # we make a prediction with our model\n",
    "        output = model(x)\n",
    "\n",
    "        # we determine the classification loss\n",
    "        loss_val = loss(output, y)\n",
    "\n",
    "        # we write the mini-nbatch loss and accuracy into the corresponding lists\n",
    "        test_accs.append(accuracy(torch.argmax(output, dim=1), y).cpu().numpy())\n",
    "\n",
    "print('test dataset accuracy:', np.mean(test_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test dataset accuracy is higher by 4 percent points, which is very nice! \n",
    "\n",
    "The beneficial effects of transfer learning on model performance are strong on small datasets, such as this one: while small datasets might be too small to train a model from scratch, fine-tuning can be very successful even on small dataset. \n",
    "\n",
    "One final note: you can easily store your trained model to a file using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'bengenet_lulc.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take this model and save it and use it for transfer learning on another task or dataset!\n",
    "\n",
    "**Exercise**: Train both the baseline and fine-tuned models for more epochs (50+). Do you observe a difference in the behaviour when it comes to overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell for the exercise"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "6e741a586f6b68b554925f4bea211b6852c45fbf3b1f1159871bb4b38b6bf4de"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
