{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dojtwAh1Ww1B"
      },
      "source": [
        "#  Image Classification with Multilayer Perceptrons\n",
        "\n",
        "*HFT Stuttgart, 2024 Summer Term, Michael Mommert (michael.mommert@hft-stuttgart.de)*\n",
        "\n",
        "Multilayer Perceptrons (MLPs) represent in some sense the simplest implementation of an artificial neural network. We will build an MLP from scratch with PyTorch and train it on the task of image classification. For this purpose, we will use the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist).\n",
        "\n",
        "This Notebook is based on work by the amazing Dr. Marco Schreyer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik2OZT8PsCBm"
      },
      "outputs": [],
      "source": [
        "%pip install numpy \\\n",
        "    matplotlib \\\n",
        "    scikit-learn \\\n",
        "    seaborn \\\n",
        "    torch \\\n",
        "    tqdm \\\n",
        "    torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rDvIKj-Ww1P"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# import the PyTorch deep learning libary\n",
        "import torch, torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "\n",
        "# import sklearn classification evaluation library\n",
        "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# import progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# set fixed random seed values\n",
        "seed_value = 42\n",
        "np.random.seed(seed_value) # set Numpy seed\n",
        "torch.manual_seed(seed_value) # set Pytorch seed for both CPU and GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHMs9Gf0wakv"
      },
      "source": [
        "Google Colab provides free GPUs for running notebooks. However, if you just execute this notebook as is, it will use your device's CPU (as if you were running the notebook on Bilder or some other cloud computing service). To run the notebook on a GPU at Colab, you have to go to `Runtime` > `Change runtime type` and set the Runtime type to `GPU` in the drop-down. Running this lab on a CPU is fine, but you will find that GPU computing is faster. `cuda:0` indicates that the notebook  is using a GPU.\n",
        "\n",
        "Enable GPU computing by setting the device flag and init a CUDA seed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl2UHzshwdyk"
      },
      "outputs": [],
      "source": [
        "# set cpu or gpu enabled device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
        "\n",
        "# init deterministic GPU seed\n",
        "torch.cuda.manual_seed(seed_value)\n",
        "\n",
        "# log type of device enabled\n",
        "print('[LOG] notebook with {} computation enabled'.format(str(device)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47HnxJHswf05"
      },
      "source": [
        "Let's determine if we have access to a GPU provided by e.g. `Google's Colab` environment (this will result in an error message, if you do not have access to a GPU):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "907R1nhVwhXb"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyqnqndjWw1S"
      },
      "source": [
        "## Dataset Download and Data Assessment\n",
        "\n",
        "The **Fashion-MNIST database** is an image dataset containing a total of 70,000 images of clothing and accessories. The dataset is divided into a set of **60,000 training examples** and a set of **10,000 evaluation examples**. Each example is a **28x28 grayscale image**, associated with a **label from 10 classes**. Zalando created this dataset with the intention of providing a replacement for the popular **MNIST** handwritten digits dataset. It is a useful addition as it is a bit more complex, but still very easy to use. It shares the same image size and train/test split structure as MNIST, and can therefore be used as a drop-in replacement. It requires minimal efforts on preprocessing and formatting the distinct images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igSTsQMKWw1U"
      },
      "source": [
        "Let's download and inspect the training images of the dataset. Therefore, let's first define the directory in which we aim to store the training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfCn1e8MWw1V"
      },
      "outputs": [],
      "source": [
        "data_directory = 'data/'\n",
        "if not os.path.exists(data_directory):\n",
        "    os.mkdir(data_directory)\n",
        "train_path = data_directory + '/train'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4fUsNeLWw1V"
      },
      "source": [
        "Now, let's download the training data accordingly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-GZL31YWw1W"
      },
      "outputs": [],
      "source": [
        "# download and transform training images\n",
        "fashion_mnist_train = torchvision.datasets.FashionMNIST(root=train_path, train=True, download=True)\n",
        "\n",
        "# split data (X) from labels (y)\n",
        "X_train = fashion_mnist_train.data\n",
        "y_train = fashion_mnist_train.targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaLuUXc4Ww1W"
      },
      "source": [
        "Verify the number of training images downloaded:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmRdyfxFWw1W"
      },
      "outputs": [],
      "source": [
        "# determine the number of training data images\n",
        "len(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtbIaCpLWw1W"
      },
      "source": [
        "Let's have a look at some of the downloaded training images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAtYOeUPWw1X"
      },
      "outputs": [],
      "source": [
        "# select some random image ids\n",
        "image_ids = np.random.randint(0, len(X_train), size=9)\n",
        "\n",
        "# retrieve images and labels\n",
        "images = X_train[image_ids]\n",
        "labels = y_train[image_ids]\n",
        "\n",
        "# create plot\n",
        "f, ax = plt.subplots(3, 3, figsize=(9, 9))\n",
        "ax = np.ravel(ax)\n",
        "\n",
        "# plot each image\n",
        "for i in range(len(images)):\n",
        "    ax[i].imshow(images[i], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SSorDiP_uFc"
      },
      "source": [
        "Nice. Let's check what the corresponding ground truth labels are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qivMa3xGsCB8"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJy8b7pasCB9"
      },
      "source": [
        "Ok, we know that the numerical label is 6. Each image is associated with a label from 0 to 9, and this number represents one of the fashion items. So what does 6 mean? Is 6 a bag? A pullover? The order of the classes can be found on Zalando research's [github page](https://github.com/zalandoresearch/fashion-mnist). We need to map each numerical label to its fashion item, which will be useful throughout the lab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weOc_Ceb_5dU"
      },
      "outputs": [],
      "source": [
        "fashion_classes = {0: 'T-shirt/top',\n",
        "                   1: 'Trouser',\n",
        "                   2: 'Pullover',\n",
        "                   3: 'Dress',\n",
        "                   4: 'Coat',\n",
        "                   5: 'Sandal',\n",
        "                   6: 'Shirt',\n",
        "                   7: 'Sneaker',\n",
        "                   8: 'Bag',\n",
        "                   9: 'Ankle boot'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctD4Dl0C_7RE"
      },
      "source": [
        "So, now we can do the translation (we need `.item()` to turn the tensor into an integer) and use the labels as titles in our figure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8KrM8rfKnHh"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(3, 3, figsize=(9, 9))\n",
        "ax = np.ravel(ax)\n",
        "\n",
        "for i in range(len(images)):\n",
        "    ax[i].imshow(images[i], cmap='gray')\n",
        "    ax[i].set_title(fashion_classes[labels[i].item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5fmhiuzWw1Y"
      },
      "source": [
        "Fantastic, right? Let's now download the evaluation data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8G3eQFy3Ww1b"
      },
      "outputs": [],
      "source": [
        "eval_path = data_directory + '/eval'\n",
        "\n",
        "# download and transform training images\n",
        "fashion_mnist_eval = torchvision.datasets.FashionMNIST(root=eval_path, train=False, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IziLcFnAsCCB"
      },
      "source": [
        "We will now split the evaluation dataset into equally sized chunks as our validation and test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6GYIFQusCCB"
      },
      "outputs": [],
      "source": [
        "X_val, X_test, y_val, y_test = train_test_split(fashion_mnist_eval.data, fashion_mnist_eval.targets, test_size=0.5, stratify=fashion_mnist_eval.targets, random_state=seed_value)\n",
        "X_val.shape, X_test.shape, y_val.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucTxc7GGWw1c"
      },
      "source": [
        "## Neural Network Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTQ_VZWaWw1d"
      },
      "source": [
        "In this section we will implement the architecture of the MLP we will use to classify the 28x28 pixel FashionMNIST images.\n",
        "\n",
        "First, let's define the input and output of the network, which will be implemented as Pytorch tensors (they work very similar to Numpy arrays, but they can be used on GPUs):\n",
        "* **Input**: the input will consist of a mini-batch of FashionMNIST images. The images are greyscale images, so there is only a single band and each image has the dimensions 28x28 pixels. For a batch size `m`, the input tensor has the shape `[m, 1, 28, 28]`; this shape follows the general convention `[batch, channel, height, width]`.\n",
        "* **Output**: we want to be able to classify our input images with 10 different classes available. Since each image can only have a single class label, we treat this problem as a multiclass classification problem. Therefore, our model will output a tensor of shape `[m, 10]`: for each image in the mini-batch, there will be 10 numbers, which we call logits - these are the activations of our model for the 10 different classes. The highest logit marks the class that our model predicts. Finally, we add a **Logsoftmax function** that turns the logits of one input image into a vector of numbers, the sum of which is normalized to unity, so we can use them as probabilities across the available classes.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyofP39KWw1d"
      },
      "source": [
        "### Implementation of the Neural Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loUEinm1Ww1e"
      },
      "source": [
        "Our MLP, which we define as a class named `MLP`, consists of three fully-connected or linear layers. Furthermore, our MLP should encompass the following number of neurons per layer: 100 (layer 1), 50 (layer 2) and 10 (layer 3). Meaning the first layer consists of 100 neurons, the second layer of 50 neurons and third layer of 10 neurons (the number of classes we aim to classify)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLrELu2EWw1f"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):  # our MLP class inherits functionality from the module nn.Module\n",
        "\n",
        "    # define the class constructor\n",
        "    def __init__(self):\n",
        "        \"\"\"In the constructor we define the components that we use in our architecture. \"\"\"\n",
        "        super(MLP, self).__init__()  # call super class constructor\n",
        "\n",
        "        self.linear1 = nn.Linear(28*28, 100)  # first linear layer (input layer): 28x28 input values to 100 output values\n",
        "        self.linear2 = nn.Linear(100, 50)  # second linear layer: 100 input values to 50 output values\n",
        "        self.linear3 = nn.Linear(50, 10)  # third lineary layer (output layer): 50 input values to 10 output values\n",
        "\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)  # logsoftmax function to turn logits into values that we can use as probabilities\n",
        "        self.relu = nn.ReLU(inplace=True)  # ReLU activation function\n",
        "\n",
        "    # define network forward pass\n",
        "    def forward(self, images):\n",
        "        \"\"\"The forward method defines how the components defined in the constructor are put together. Note that the forward\n",
        "        pass is defined for a single sample of the mini-batch, which simplifies the setup considerably.\"\"\"\n",
        "\n",
        "        # linearize image\n",
        "        x = images.float().view(-1, 28*28)\n",
        "        x = self.relu(self.linear1(x))  # run the data through the first linear layer and ReLU\n",
        "        x = self.relu(self.linear2(x))  # run the data through the second linear layer and ReLU\n",
        "        x = self.logsoftmax(self.linear3(x))  # run the data through the third linear layer and the logsoftmax function\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcrCZgZqWw1g"
      },
      "source": [
        "Now, that we have implemented our first neural network we are ready to instantiate the model and push it to the GPU for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfvFFCCHWw1g"
      },
      "outputs": [],
      "source": [
        "model = MLP()\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFKJMIjKWw1g"
      },
      "source": [
        "Finally, let's have a look into the number of model parameters that we aim to train in the next steps of the notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFOWHzJ3Ww1h"
      },
      "outputs": [],
      "source": [
        "num_params = 0\n",
        "for param in model.parameters():  # iterate over the trainable parameters in our architecture\n",
        "    num_params += param.numel()  # collect number of parameters\n",
        "\n",
        "print(num_params, 'parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKbH8GgrWw1i"
      },
      "source": [
        "## Neural Network Model Training\n",
        "\n",
        "### Training Setup\n",
        "\n",
        "Before we can start the training process, we have to define a few more things.\n",
        "\n",
        "First, we have to define a **Loss Function** that will guide our model in its training process. Remember, the training objective is to learn a set of optimal model parameters $\\theta^*$ that optimize $\\arg\\min_{\\theta} \\|C - f_\\theta(X)\\|$ over all training images in the FashionMNIST dataset. To achieve this optimization objective, one typically minimizes a loss function $\\mathcal{L_{\\theta}}$ as part of the network training. We will use the **'Negative Log Likelihood (NLL)'** loss, which is commonly used for multiclass classification problems. NLL loss is defined as follows:\n",
        "\n",
        "$$\\mathcal{L}^{NLL}_{\\theta} (c_i, \\hat c_i) = - \\frac{1}{N} \\sum_{i=1}^N \\log (\\hat{c}_i) $$\n",
        "\n",
        "for a set of $n$ images $x^{i}$, $i=1,...,n$ and their respective predicted class labels $\\hat{c}^{i}$. This is summed for all the correct classes.\n",
        "\n",
        "We instantiate the NLL loss and push it to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzfYahsCsCCF"
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsXK4EwpsCCF"
      },
      "source": [
        "Based on the loss value of a specific mini-batch sample, PyTorch automatically computes the gradients. Based on the gradients, and the chosen **optimizer**, Pytorch will  update the network parameters $\\theta$ to facilitate the learning process for our model.\n",
        "\n",
        "We will use **Stochastic Gradient Descent (SGD) optimization** and set the learning-rate $l = 0.0001$. Each mini-batch step the optimizer will update the model parameters $\\theta$ values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEkObshhsCCF"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.0001\n",
        "optimizer = optim.SGD(model.parameters(), learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fClGyWPGsCCG"
      },
      "source": [
        "Finally, we have to define the **number of epochs** for which we would like to train the model - let's pick 10 - and the **batch size** for the training process. The batch size is actually a model hyperparameter that affects the learning of the model: higher batch size lead to a smoother learning process, since the gradients computed during backpropagation are averaged over more samples. However, since the batch size is also directly correlated to the learning rate, one typically picks a large batch size (to use the GPU efficiently) and only modifies the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bMEnxc1Ww1j"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10  # number of training epochs\n",
        "mini_batch_size = 128  # size of the mini-batches in the training process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO1P2wb3Ww1k"
      },
      "source": [
        "The final ingredient for the training process are the **dataloaders**. Dataloaders are classes provided by Pytorch that provide the dataset in the required format (`[mini batch, channels, height, width]`). We need one dataloader for each of the dataset splits (the mini batch sizes for val and test equal the sizes of these datasets for quicker processing):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyLwFEMXWw1l"
      },
      "outputs": [],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(list(zip(X_train, y_train)), batch_size=mini_batch_size, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(list(zip(X_val, y_val)), batch_size=len(X_val))\n",
        "test_dataloader = torch.utils.data.DataLoader(list(zip(X_test, y_test)), batch_size=len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp6hmrg7Ww1l"
      },
      "source": [
        "### Training Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov5Z6NLvWw1m"
      },
      "source": [
        "Now we can start the model training process. The detailed training procedure for each mini-batch is performed as follows:\n",
        "\n",
        ">1. do a forward pass through the model,\n",
        ">2. compute the negative log likelihood loss value,\n",
        ">3. do a backward pass through the model, and\n",
        ">4. update the parameters of the model.\n",
        "\n",
        "For each training epoch, we will monitor the training and validation loss. While the former is used to evaluate whether the model learns anything useful, the latter is used to check for potential overfitting of the model. Furthermore, we will also monitor the accuracy on the training and validation datasets.\n",
        "\n",
        "The following elements of the network training code below should be given particular attention:\n",
        "\n",
        ">- `loss.backward()` computes the gradients based on the magnitude of the reconstruction loss,\n",
        ">- `optimizer.step()` updates the network parameters based on the gradient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70W8AZWlWw1m"
      },
      "outputs": [],
      "source": [
        "train_epoch_losses = []  # here we will store the training losses\n",
        "val_epoch_losses = []  # here we will store the validation losses\n",
        "train_epoch_accs = []  # here we will store the training accuracies\n",
        "val_epoch_accs = []  # here we will store the validation accuracies\n",
        "\n",
        "# iterate over epochs\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # training process ------------------------------------\n",
        "    model.train()  # set the model in training mode\n",
        "    train_mini_batch_losses = []\n",
        "    train_mini_batch_accs = []\n",
        "    # iterate over mini batches\n",
        "    for i, (images, labels) in tqdm(enumerate(train_dataloader)):\n",
        "        images = images.to(device)  # push images to GPU\n",
        "        labels = labels.to(device)  # push labels to GPU\n",
        "\n",
        "        output = model(images)  # forward pass\n",
        "\n",
        "        model.zero_grad()  # reset gradients\n",
        "\n",
        "        loss = criterion(output, labels)  # compute loss\n",
        "\n",
        "        loss.backward()  # perform backprop\n",
        "        optimizer.step()  # update model paramaters\n",
        "\n",
        "        train_mini_batch_losses.append(loss.data.item())  # extract mini batch loss\n",
        "\n",
        "        # compute accuracy\n",
        "        train_mini_batch_accs.append(\n",
        "            accuracy_score(labels.cpu().numpy(),\n",
        "                           torch.argmax(output, dim=1).cpu().numpy()))\n",
        "\n",
        "    # compute mean training loss and accuracy over all mini batches\n",
        "    train_epoch_losses.append(np.mean(train_mini_batch_losses))\n",
        "    train_epoch_accs.append(np.mean(train_mini_batch_accs))\n",
        "\n",
        "    # evaluation process ------------------------------------\n",
        "    model.eval()  # set the model in evaluation mode\n",
        "    val_mini_batch_losses = []\n",
        "    val_mini_batch_accs = []\n",
        "    # iterate over mini batches\n",
        "    with torch.no_grad():  # deactivate computational graph (saves memory)\n",
        "        for i, (images, labels) in tqdm(enumerate(val_dataloader)):\n",
        "            images = images.to(device)  # push images to GPU\n",
        "            labels = labels.to(device)  # push labels to GPU\n",
        "\n",
        "            output = model(images)  # forward pass\n",
        "            loss = criterion(output, labels)  # compute loss\n",
        "            val_mini_batch_losses.append(loss.data.item())  # extract mini batch loss\n",
        "\n",
        "            # compute accuracy\n",
        "            val_mini_batch_accs.append(\n",
        "                accuracy_score(labels.cpu().numpy(),\n",
        "                               torch.argmax(output, dim=1).cpu().numpy()))\n",
        "\n",
        "\n",
        "    # compute mean validation loss and accuracy over all mini batches\n",
        "    val_epoch_losses.append(np.mean(val_mini_batch_losses))\n",
        "    val_epoch_accs.append(np.mean(val_mini_batch_accs))\n",
        "\n",
        "    print('epoch: {}, train-loss: {:.5f}, val-loss: {:.5f} train-acc: {:.3f}, val-acc: {:.3f}'.format(\n",
        "        epoch, train_epoch_losses[-1], val_epoch_losses[-1], train_epoch_accs[-1], val_epoch_accs[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dqoGo_7Ww1m"
      },
      "source": [
        "Let's plot the loss and accuracy curves:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLI0Y53VWw1m"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(1, 2, sharex=True, figsize=(10, 5))\n",
        "\n",
        "# plot losses\n",
        "ax[0].plot(np.array(range(1, len(train_epoch_losses)+1)), train_epoch_losses, color='red', label='train')\n",
        "ax[0].plot(np.array(range(1, len(val_epoch_losses)+1)), val_epoch_losses, color='blue', label='val')\n",
        "\n",
        "# plot accuracies\n",
        "ax[1].plot(np.array(range(1, len(train_epoch_accs)+1)), train_epoch_accs, color='red', label='train')\n",
        "ax[1].plot(np.array(range(1, len(val_epoch_accs)+1)), val_epoch_accs, color='blue', label='val')\n",
        "\n",
        "# add axis labels\n",
        "ax[0].set_xlabel(\"Epoch\")\n",
        "ax[1].set_xlabel(\"Epoch\")\n",
        "ax[0].set_ylabel(\"Loss\")\n",
        "ax[1].set_ylabel(\"Accuracy\")\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmkQMB6YWw1n"
      },
      "source": [
        "This looks good: the loss values decrease while the accuracies increase. Also, the metrics on the different dataset move in parallel, which rules out overfitting.\n",
        "\n",
        "We could train the network a couple more epochs until the error converges. But let's stick to 10 training epochs for now and continue with evaluating our trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nyWq1X-Ww1n"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPP7OowBWw1o"
      },
      "source": [
        "We will now evaluate the trained model using the same approach but based on the test dataset this time. The goal is compute the accuracy on the test dataset to get a final evaluation of our model results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpttWy_AWw1o"
      },
      "outputs": [],
      "source": [
        "model.eval()  # set the model in evaluation mode\n",
        "test_mini_batch_accs = []\n",
        "with torch.no_grad():  # deactivate computational graph (saves memory)\n",
        "    # iterate over mini batches\n",
        "    for i, (images, labels) in tqdm(enumerate(test_dataloader)):\n",
        "\n",
        "        images = images.to(device)  # push images to GPU\n",
        "        labels = labels.to(device)  # push labels to GPU\n",
        "\n",
        "        output = model(images)  # forward pass\n",
        "        test_mini_batch_accs.append(\n",
        "            accuracy_score(labels.cpu().numpy(),\n",
        "                           torch.argmax(output, dim=1).cpu().numpy()))\n",
        "\n",
        "\n",
        "# compute mean accuracy over all mini batches\n",
        "test_accuracy = np.mean(test_mini_batch_accs)\n",
        "\n",
        "print('test dataset accuracy', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNwLBDGPWw1p"
      },
      "source": [
        "Ok, great. The test dataset accuracy is close to the validation accuracy, which is also a good sign.\n",
        "\n",
        "Let's pick a sample image and predict its class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTM5mTHaWw1p"
      },
      "outputs": [],
      "source": [
        "image_id = 42\n",
        "\n",
        "# retrieve image and label data\n",
        "image, label = X_test[image_id].to(device), y_test[image_id]\n",
        "\n",
        "output = model(image)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNFAM_deWw1s"
      },
      "source": [
        "Remind yourself of what we are looking at: each element of the vector may be interpreted as a probability that the image shows this class (according to our model).\n",
        "\n",
        "Let's identify the most probable class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2knLiUqWw1t"
      },
      "outputs": [],
      "source": [
        "most_probable = torch.argmax(output, dim=1).item()\n",
        "print('Most probable class: {}'.format(most_probable))\n",
        "print('This class represents the following product:', fashion_classes[most_probable])\n",
        "print('Actual product class:', fashion_classes[label.item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj-HTBbisCCM"
      },
      "source": [
        "Great, it works!\n",
        "\n",
        "This is it. We created a neural network from scratch and trained it to identify different fashion products.\n",
        "\n",
        "**Exercise**: Compile the necessary code from above and perform a hyperparameter tuning to identify and evaluate the best-performing model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJDFXq8csCCM"
      },
      "outputs": [],
      "source": [
        "# use this cell for the exercise"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
      ],
      "name": "mlp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "248px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}